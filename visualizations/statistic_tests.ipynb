{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "metrics = ['f1_cd','f1_ln']\n",
    "mappings = ['incremental','procrustes','twec']\n",
    "w2vec_algorithms = ['word2vec','lda2vec']\n",
    "embeddings = ['pretrained','None']\n",
    "results_path = './output/**/**/results'\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "path = '../output/**/**/results'\n",
    "text_files = set(glob.glob(path + \"/**/*.pkl\", recursive=True))\n",
    "for file in text_files:\n",
    "    results_df = pd.concat([results_df, pd.read_pickle(file)], ignore_index=True, axis=0)\n",
    "\n",
    "results_df.to_csv('../language_drift_results', index=False)\n",
    "\n",
    "results_df = pd.read_csv('../language_drift_results')\n",
    "print(results_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Research Questions\n",
    "### 1. Which vectors' alignment method performs better?\n",
    "\n",
    "### Null Hypothesis: \n",
    "Αll mapping methods we investigate(‘procrustes’, ‘incremental’, ‘twec’) perform equally across different executions on the same datasets and parameters.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deep copy\n",
    "mapping_df = results_df.copy(deep=True)\n",
    "# remove \"lda2vec\" and \"pretrained\" executions\n",
    "mapping_df = mapping_df.drop(mapping_df[((mapping_df['pretrained'] != 'None') \n",
    "                                         | (mapping_df['w2vec_algorithm'] == 'lda2vec'))].index)\n",
    "                                         \n",
    "# remove unnecessary columns\n",
    "mapping_df = mapping_df.drop(['precision_cd','precision_ln','accuracy_cd','accuracy_ln',\n",
    "          'recall_cd','recall_ln','data_set_id','dim','window_size','pretrained','t'],axis=1)\n",
    "\n",
    "mapping_df = mapping_df.melt(id_vars=[\"language\", \"w2vec_algorithm\",\"mapping\"], \n",
    "        var_name=\"metric\", \n",
    "        value_name=\"f1_score\")\n",
    "\n",
    "\n",
    "# remove rows with Nan values at f1_scores \n",
    "mapping_df = mapping_df[mapping_df['f1_score'].notna()]\n",
    "\n",
    "# remove unnecessary columns\n",
    "mapping_df = mapping_df.drop('metric',axis=1)\n",
    "\n",
    "# create pivot table\n",
    "#pivot_mappings = mapping_df.pivot_table(index=['language','w2vec_algorithm'], columns=\"mapping\", values=['f1_score']).reset_index()\n",
    "#pivot_cd['mean_f1'] = pivot_cd.loc[:, (['f1_cd','f1_ln'], slice(None))].mean(axis=1)\n",
    "print(mapping_df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Shapiro-Wilk Test (checks normality of distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Shapiro-Wilk test for normal distribution: \\n\")\n",
    "mapping_normality_dict = defaultdict()\n",
    "for mapping in mappings:\n",
    "    stat, p = stats.shapiro( mapping_df.loc[mapping_df['mapping'] == str(mapping),'f1_score'])\n",
    "    print(mapping)\n",
    "    if p >= alpha:\n",
    "        print(\"\\t has a normal distribution with pvalue = \"+ str(p) + \", stat=\",str(stat))\n",
    "        mapping_normality_dict[mapping] = True\n",
    "    else:\n",
    "        print(\"\\t has NOT a normal distribution with pvalue = \", p, \"stat=\",stat)\n",
    "        mapping_normality_dict[mapping] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normality Results\n",
    "**Incremental** and **twec** method can be described by the normal distribution.\n",
    "\n",
    "However since **procrustes** method does not meet the criteria of the normality <u>we have to go through with non parapetric tests.</u>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Friedman test (non parametric - normality is not a prerequisite)\n",
    "* Prerequisites (non normal distributions, paired samples, more than two groups)\n",
    "* Samples are paired since all variables except the under investigation variable are shared among the different populations\n",
    "* H0: Populations have same distributions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Friedman test (non parametric - normality is not a prerequisite)\n",
    "# Compare groups of incremental, procrustes and twec\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Friedman H-test: \\n\\n incremental-procrustes\")\n",
    "stat, p = stats.friedmanchisquare(\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'incremental','f1_score'],\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'procrustes','f1_score'],\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'twec','f1_score'])\n",
    "\n",
    "if p >= alpha:\n",
    "    print(\"    Same distributions (fail to reject H0) with pvalue = \",p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Different distributions (reject H0) = \", p, \"stat=\",stat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 1.3 Wilcoxon Signed-Rank Test (non parametric - normality is not a prerequisite)\n",
    "* Prerequisites (non normal distributions, paired samples, two populations)\n",
    "* Samples are paired since all variables except the under investigation variable are shared among the different populations\n",
    "* H0: Populations have same distributions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wilcoxon Signed-Rank Test (non parametric - normality is not a prerequisite)\n",
    "# Compare groups of incremental, procrustes and twec\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Wilcoxon Signed-Rank H-test: \\n\\n incremental-procrustes\")\n",
    "stat, p = stats.wilcoxon(\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'incremental','f1_score'],\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'procrustes','f1_score'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"    Null Hypothesis REJECTED with pvalue = \", p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Null hypothesis was ACCEPTED with pvalue = \",p, \"stat=\",stat)\n",
    "    \n",
    "print(\"\\n incremental-twec\")\n",
    "stat, p = stats.wilcoxon(\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'incremental','f1_score'],\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'twec','f1_score'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"    Null Hypothesis REJECTED with pvalue = \", p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Null hypothesis was ACCEPTED with pvalue = \",p, \"stat=\",stat)\n",
    "\n",
    "print(\"\\n procrustes-twec\")\n",
    "stat, p = stats.wilcoxon(\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'procrustes','f1_score'],\n",
    "    mapping_df.loc[mapping_df['mapping'] == 'twec','f1_score'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"    Null Hypothesis REJECTED with pvalue = \", p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Null hypothesis was ACCEPTED with pvalue = \",p, \"stat=\",stat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Results\n",
    "After the execution on the following combinations:\n",
    "- **cbow-sgns** (algorithm)\n",
    "- **incremental-procrustes-twec** (alignment)\n",
    "- **en-de-swe-lat** (languages)\n",
    "- **cd-ln** (metrics of cosine distance and local_neighborhood measure)\n",
    "\n",
    "On the following **Word2Vec** parameter setting:\n",
    "- **embeddings_dimension = 100**\n",
    "- **window_size = 10**\n",
    "- **min_count = 3** (number of occurences)\n",
    "- **s = 0.001** (threshold for configuring which higher-frequency words are randomly downsampled)\n",
    "- **k = 5** number of negative samples parameter \n",
    "- **epochs = 5**\n",
    "\n",
    "We investigated the f1_scores of **48** executions (algorithms * alignmen * languages * metrics).\n",
    "\n",
    "The result was that **there are no significate differences between the embeddings' alignment methods we used**.\n",
    "We need to mention that there were not executions with pretrained embeddings at the above analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot( saturation=1, palette='BuGn',ax=ax, whis=[5, 95],x=mapping_df['mapping'],y=mapping_df['f1_score'])\n",
    "# specify axis labels\n",
    "plt.xlabel('', size=14, family='monospace')\n",
    "plt.ylabel('', size=14, family='monospace')\n",
    "plt.title('F1 Scores per Alignment Method')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Research Questions\n",
    "### 2. Do pretrained embeddings improve performance? in cases of procrustes and incremental alignment methods?\n",
    "\n",
    "### Null Hypothesis: \n",
    "Executions with pretrained embeddings perform equally with those that haven't been prior initialized.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deep copy\n",
    "pretrained_df = results_df.copy(deep=True)\n",
    "# remove \"lda2vec\" and \"twec\" executions\n",
    "pretrained_df = pretrained_df.drop(pretrained_df[((pretrained_df['mapping'] == 'twec') \n",
    "                                         | (pretrained_df['w2vec_algorithm'] == 'lda2vec'))].index)\n",
    "                                         \n",
    "# remove unnecessary columns\n",
    "pretrained_df = pretrained_df.drop(['precision_cd','precision_ln','accuracy_cd','accuracy_ln',\n",
    "          'recall_cd','recall_ln','data_set_id','dim','window_size','mapping','t'],axis=1)\n",
    "\n",
    "pretrained_df = pretrained_df.melt(id_vars=[\"language\", \"w2vec_algorithm\",\"pretrained\"], \n",
    "        var_name=\"metric\", \n",
    "        value_name=\"f1_score\")\n",
    "\n",
    "\n",
    "# remove rows with Nan values at f1_scores \n",
    "pretrained_df = pretrained_df[pretrained_df['f1_score'].notna()]\n",
    "\n",
    "# remove unnecessary columns\n",
    "pretrained_df = pretrained_df.drop('metric',axis=1)\n",
    "\n",
    "print(pretrained_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Shapiro-Wilk Test (checks normality of distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Shapiro-Wilk test for normal distribution: \\n\")\n",
    "embedding_normality_dict = defaultdict()\n",
    "for embedding in embeddings:\n",
    "    if embedding == 'None':\n",
    "        stat, p = stats.shapiro( pretrained_df.loc[pretrained_df['pretrained'] == 'None','f1_score'])\n",
    "    else:\n",
    "        stat, p = stats.shapiro( pretrained_df.loc[pretrained_df['pretrained'] != 'None','f1_score'])\n",
    "    print(embedding)\n",
    "    if p >= alpha:\n",
    "        print(\"\\t has a normal distribution with pvalue = \"+ str(p) + \", stat=\",str(stat))\n",
    "        embedding_normality_dict[embedding] = True\n",
    "    else:\n",
    "        print(\"\\t has NOT a normal distribution with pvalue = \", p, \"stat=\",stat)\n",
    "        embedding_normality_dict[embedding] = False\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normality Results\n",
    "Executions with usage of **Pretrained** embeddings and **Non Pretained** embeddings can be described by the normal distribution.\n",
    "\n",
    "The next step is to conduct a **paired-T test**.</u>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Paired T-Test (parametric - normality is  a prerequisite)\n",
    "- Prerequisites:\n",
    "\n",
    "    - normal distribution of dependent variable\n",
    "    - continuous dependent variable\n",
    "    - independent observations \n",
    "    - same subject for each group \n",
    "    - dependent variable does not contain outliers. \n",
    "  \n",
    "- H0: means of the populations are equal to zero\n",
    "* H1: p1 is not equal to p2  || p1 – p2 is not equal to zero.\n",
    "\n",
    "**Samples are paired** since all variables except the under investigation variable are shared among the different populations\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ensure we don't have any outliers\n",
    "# IQR\n",
    "Q1 = np.percentile(pretrained_df.loc[(pretrained_df['pretrained'] != 'None'), ['f1_score']], \n",
    "                   25,interpolation = 'midpoint')\n",
    " \n",
    "Q3 = np.percentile(pretrained_df.loc[(pretrained_df['pretrained'] != 'None'), ['f1_score']], \n",
    "           75,interpolation = 'midpoint')\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "# Above Upper bound\n",
    "upper = pretrained_df['f1_score'] >= (Q3+1.5*IQR)\n",
    " \n",
    "print(\"Upper bound:\",upper)\n",
    "#print(np.where(upper))\n",
    " \n",
    "# Below Lower bound\n",
    "lower = pretrained_df['f1_score'] <= (Q1-1.5*IQR)\n",
    "print(\"Lower bound:\", lower)\n",
    "#print(np.where(lower))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Paired T-Test (parametric - normality is not a prerequisite)\n",
    "# Compare groups of incremental, procrustes and twec\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Paired T-Test H-test: \\n\\n pretrained - NOT pretrained\")\n",
    "stat, p = stats.ttest_rel(\n",
    "    pretrained_df.loc[pretrained_df['pretrained'] != 'None','f1_score'],\n",
    "    pretrained_df.loc[pretrained_df['pretrained'] == 'None','f1_score'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"    Null Hypothesis REJECTED with pvalue = \", p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Null hypothesis was ACCEPTED with pvalue = \",p, \"stat=\",stat)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Results\n",
    "After the execution on the following combinations:\n",
    "- **cbow-sgns** (algorithm)\n",
    "- **incremental-procrustes** (alignment)\n",
    "- **en-de-swe-lat** (languages)\n",
    "- **cd-ln** (metrics of cosine distance and local_neighborhood measure)\n",
    "\n",
    "On the following **Word2Vec** parameter setting:\n",
    "- **embeddings_dimension = 100**\n",
    "- **window_size = 10**\n",
    "- **min_count = 3** (number of occurences)\n",
    "- **s = 0.001** (threshold for configuring which higher-frequency words are randomly downsampled)\n",
    "- **k = 5** number of negative samples parameter \n",
    "- **epochs = 5**\n",
    "\n",
    "For half of the samples vector weights were prior initialized with pretrained embeddings.\n",
    "\n",
    "We investigated the f1_scores of **64 executions** (algorithms * alignmen * languages * metrics).\n",
    "\n",
    "The result was that **there are significate differences** between the model which were prior initialized and those hadn't.\n",
    "We need to mention that there were not executions with twec alignment method at the above analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "pretrained_df.loc[pretrained_df[\"pretrained\"] != \"None\", \"pretrained\"] = \"pretrained\"\n",
    "sns.boxplot( saturation=1, palette='BuGn',ax=ax, whis=[5, 95],x=pretrained_df['pretrained'],y=pretrained_df['f1_score'])\n",
    "# specify axis labels\n",
    "plt.xlabel('', size=14, family='monospace')\n",
    "plt.ylabel('', size=14, family='monospace')\n",
    "plt.title('F1 Scores per type of embeddings')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Research Questions\n",
    "### 3. Lda2Vec and word2vec models performs the same?\n",
    "\n",
    "### Null Hypothesis: \n",
    "Executions with lda2vec equally perform with those from a word2vec across different executions on the same datasets and parameters.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deep copy\n",
    "model_df = results_df.copy(deep=True)\n",
    "# remove \"lda2vec\" and \"pretrained\" executions\n",
    "model_df = model_df.drop(model_df[((model_df['pretrained'] != 'None') )].index)\n",
    "                                         \n",
    "# remove unnecessary columns\n",
    "model_df = model_df.drop(['precision_cd','precision_ln','accuracy_cd','accuracy_ln',\n",
    "          'recall_cd','recall_ln','data_set_id','dim','window_size','pretrained','t'],axis=1)\n",
    "\n",
    "model_df = model_df.melt(id_vars=[\"language\", \"w2vec_algorithm\",\"mapping\"], \n",
    "        var_name=\"metric\", \n",
    "        value_name=\"f1_score\")\n",
    "\n",
    "\n",
    "# remove rows with Nan values at f1_scores \n",
    "model_df = model_df[model_df['f1_score'].notna()]\n",
    "\n",
    "# transform cbow/sgns to word2vec\n",
    "model_df[\"w2vec_algorithm\"] = np.where(model_df[\"w2vec_algorithm\"] == \"lda2vec\", 'lda2vec', 'word2vec')\n",
    "\n",
    "\n",
    "# keep experiments with same mapping method of lda2vec and word2vec\n",
    "model_df = model_df[(model_df['mapping'] == 'procrustes') ]\n",
    "\n",
    "# keep experiments with same language\n",
    "model_df = model_df[model_df['language'].isin(['en','lat'])]\n",
    "\n",
    "# remove unnecessary columns\n",
    "model_df = model_df.drop('metric',axis=1)\n",
    "\n",
    "print(model_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Shapiro-Wilk Test (checks normality of distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05\n",
    "count = 0\n",
    "\n",
    "print(\"Shapiro-Wilk test for normal distribution: \\n\")\n",
    "model_normality_dict = defaultdict()\n",
    "for w2vec_algorith in w2vec_algorithms:\n",
    "    if w2vec_algorith in 'lda2vec':\n",
    "        stat, p = stats.shapiro( model_df.loc[model_df['w2vec_algorithm'] == w2vec_algorith,'f1_score'])\n",
    "    else:\n",
    "        count +=1\n",
    "        stat, p = stats.shapiro( model_df.loc[model_df['w2vec_algorithm'] != 'lda2vec','f1_score'])\n",
    "    if count==2:\n",
    "        print(\"word2vec\")\n",
    "    stat, p = stats.shapiro( model_df.loc[model_df['w2vec_algorithm'] == str(w2vec_algorith),'f1_score'])\n",
    "    if p >= alpha:\n",
    "        print(\"\\t has a normal distribution with pvalue = \"+ str(p) + \", stat=\",str(stat))\n",
    "        model_normality_dict[mapping] = True\n",
    "    else:\n",
    "        print(\"\\t has NOT a normal distribution with pvalue = \", p, \"stat=\",stat)\n",
    "        model_normality_dict[mapping] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normality Results\n",
    "**SGNS** and **CBOW** models can be described by the normal distribution.\n",
    "\n",
    "However since **Lda2Vec** method does not meet the criteria of the normality <u>we have to go through with non parapetric tests.</u>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Wilcoxon Signed-Rank Test (non parametric - normality is not a prerequisite)\n",
    "* Prerequisites (non normal distributions, paired samples, two populations)\n",
    "* Samples are paired since all variables except the under investigation variable are shared among the different populations\n",
    "* H0: Populations have same distributions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wilcoxon Signed-Rank Test (non parametric - normality is not a prerequisite)\n",
    "# Compare groups of incremental, procrustes and twec\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "print(\"Wilcoxon Signed-Rank H-test: \\n\\n lda2vec-word2vec\")\n",
    "stat, p = stats.wilcoxon(\n",
    "    model_df.loc[model_df['w2vec_algorithm'] == 'lda2vec','f1_score'],\n",
    "    model_df.loc[model_df['w2vec_algorithm'] != 'lda2vec','f1_score'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"    Null Hypothesis REJECTED with pvalue = \", p, \"stat=\",stat)\n",
    "else:\n",
    "    print(\"    Null hypothesis was ACCEPTED with pvalue = \",p, \"stat=\",stat)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Results\n",
    "The usage of pretrained embeddings improves F1 scores. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot( saturation=1, palette='BuGn',ax=ax, whis=[5, 95],x=model_df['w2vec_algorithm'],y=model_df['f1_score'])\n",
    "# specify axis labels\n",
    "plt.xlabel('', size=14, family='monospace')\n",
    "plt.ylabel('', size=14, family='monospace')\n",
    "plt.title('F1 Scores per Represenation model')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 2.3 Results\n",
    "After the execution on the following combinations:\n",
    "- **lda2vec-word2vec** (model)\n",
    "- **incremental-procrustes** (alignment)\n",
    "- **en-lat** (languages)\n",
    "- **cd-ln** (metrics of cosine distance and local_neighborhood measure)\n",
    "\n",
    "On the following **Word2Vec** parameter setting:\n",
    "- **embeddings_dimension = 100**\n",
    "- **window_size = 10**\n",
    "- **min_count = 3** (number of occurences)\n",
    "- **s = 0.001** (threshold for configuring which higher-frequency words are randomly downsampled)\n",
    "- **k = 5** number of negative samples parameter \n",
    "- **epochs = 5**\n",
    "\n",
    "For half of the samples vector weights were prior initialized with pretrained embeddings.\n",
    "\n",
    "We investigated the f1_scores of **16 executions** (models * languages * metrics).\n",
    "\n",
    "The result was that **there are significate differences** between the model which were prior initialized and those hadn't.\n",
    "We need to mention that there were not executions with twec alignment method at the above analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-thesis",
   "language": "python",
   "name": "test-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}